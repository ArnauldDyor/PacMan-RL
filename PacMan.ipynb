{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andrea\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.layers import convolution2d, fully_connected, flatten\n",
    "from collections import deque, Counter\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mspacman_color = np.array([210, 164, 74]).mean()\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[1:176:2, ::2]\n",
    "    img = img.mean(axis=2)\n",
    "    img[img==mspacman_color] = 0\n",
    "    img = (img - 128) / 128 - 1\n",
    "    return img.reshape(88,80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-03-22 09:12:14,757] Making new env: MsPacman-v0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "env = gym.make(\"MsPacman-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninput_height = 88\\ninput_width = 80\\ninput_channels = 1\\nconv_n_maps = [32, 64, 64]\\nconv_kernel_sizes = [(8,8), (4,4), (3,3)]\\nconv_strides = [4,2,1]\\nconv_paddings = ['SAME']*3\\nconv_activation = [tf.nn.relu]*3\\nn_hidden_in = 64 * 11 * 10\\nn_hidden = 512\\nhidden_activation = tf.nn.relu\\nn_outputs = env.action_space.n\\ninitializer = tf.contrib.layers.variance_scaling_initializer()\\nfrom tensorflow.contrib.layers import convolution2d, fully_connected\\ndef q_network(X_state, scope):\\n    prev_layer = X_state\\n    conv_layers = []\\n    \\n    with tf.variable_scope(scope) as scope:\\n        for n_maps, kernel_size, stride, padding, activation in zip(conv_n_maps, conv_kernel_sizes, conv_strides, \\n                                                                   conv_paddings, conv_activation):\\n            prev_layer = convolution2d(prev_layer, num_outputs=n_maps, kernel_size=kernel_size, stride=stride,\\n                                      padding=padding, activation_fn=activation, weights_initializer=initializer)\\n            conv_layers.append(prev_layer)\\n        last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\\n        hidden = fully_connected(last_conv_layer_flat, n_hidden, activation_fn=hidden_activation, weights_initializer=initializer)\\n        tf.summary.histogram('hidden',hidden)\\n        outputs = fully_connected(hidden, n_outputs, activation_fn=None, weights_initializer=initializer)\\n        tf.summary.histogram('outputs',outputs)\\n        \\n    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\\n    trainable_vars_by_name = {var.name[len(scope.name):]:var for var in trainable_vars}\\n    return trainable_vars_by_name, outputs\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_outputs = env.action_space.n\n",
    "\n",
    "def q_network(X, name_scope):\n",
    "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    with tf.variable_scope(name_scope) as scope: ## or tf.name_scope(name) ??\n",
    "        layer_1 = convolution2d(X, num_outputs=32, kernel_size=8, stride=4, padding='SAME') #ev change weights_initializer\n",
    "        layer_1_normed = tf.layers.batch_normalization(layer_1, training=in_training_mode)\n",
    "        \n",
    "        layer_2 = convolution2d(layer_1_normed, num_outputs=64, kernel_size=4, stride=2, padding='SAME')\n",
    "        layer_2_normed = tf.layers.batch_normalization(layer_2, training=in_training_mode)\n",
    "        layer_3 = convolution2d(layer_2_normed, num_outputs=64, kernel_size=3, stride=1, padding='SAME')\n",
    "        layer_3_normed = tf.layers.batch_normalization(layer_3, training=in_training_mode)\n",
    "        \n",
    "        flat = flatten(layer_3_normed)\n",
    "        fc_1 = fully_connected(flat, num_outputs=128)\n",
    "        \n",
    "        fc_1_normed = tf.layers.batch_normalization(fc_1, training=in_training_mode)\n",
    "        tf.summary.histogram('fc_1',fc_1_normed)\n",
    "        \n",
    "        outputs = fully_connected(fc_1_normed, num_outputs=n_outputs, activation_fn=None)\n",
    "        tf.summary.histogram('outputs',outputs)\n",
    "        \n",
    "        vrs = {v.name[len(scope.name):]: v for v in tf.get_collection(key=tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)} \n",
    "        return vrs, outputs\n",
    "\n",
    "'''\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32, 64, 64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4,2,1]\n",
    "conv_paddings = ['SAME']*3\n",
    "conv_activation = [tf.nn.relu]*3\n",
    "n_hidden_in = 64 * 11 * 10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "from tensorflow.contrib.layers import convolution2d, fully_connected\n",
    "def q_network(X_state, scope):\n",
    "    prev_layer = X_state\n",
    "    conv_layers = []\n",
    "    \n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        for n_maps, kernel_size, stride, padding, activation in zip(conv_n_maps, conv_kernel_sizes, conv_strides, \n",
    "                                                                   conv_paddings, conv_activation):\n",
    "            prev_layer = convolution2d(prev_layer, num_outputs=n_maps, kernel_size=kernel_size, stride=stride,\n",
    "                                      padding=padding, activation_fn=activation, weights_initializer=initializer)\n",
    "            conv_layers.append(prev_layer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "        hidden = fully_connected(last_conv_layer_flat, n_hidden, activation_fn=hidden_activation, weights_initializer=initializer)\n",
    "        tf.summary.histogram('hidden',hidden)\n",
    "        outputs = fully_connected(hidden, n_outputs, activation_fn=None, weights_initializer=initializer)\n",
    "        tf.summary.histogram('outputs',outputs)\n",
    "        \n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "    trainable_vars_by_name = {var.name[len(scope.name):]:var for var in trainable_vars}\n",
    "    return trainable_vars_by_name, outputs'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20000\n",
    "def get_memories(batch_size):\n",
    "    perm_batch = np.random.permutation(len(memories))[:batch_size]\n",
    "    mem = np.array(memories)[perm_batch]\n",
    "    return mem[:,0], mem[:,1], mem[:,2], mem[:,3], mem[:,4]\n",
    "\n",
    "epsilon = 0.5\n",
    "eps_min = 0.05\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 500000\n",
    "\n",
    "def expl_policy(action, step, print_ep=False):\n",
    "    p = np.random.random(1).squeeze()\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if print_ep:\n",
    "        print('Epsilon:',epsilon)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = 400\n",
    "batch_size = 48\n",
    "global_step = 0\n",
    "print_ep = 10\n",
    "input_shape = (None, 88, 80, 1)\n",
    "learning_rate = 0.001\n",
    "X_shape = (None, 88, 80, 1)\n",
    "discount_factor = 0.97\n",
    "copy_steps = 100\n",
    "steps_train = 4\n",
    "start_steps = 2000\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y/%m/%d-%H-%M-%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "memories = deque(maxlen=maxlen)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=X_shape)\n",
    "in_training_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "mainQ, mainQ_outputs = q_network(X, 'mainQ')\n",
    "secondQ, secondQ_outputs = q_network(X, 'secondQ')\n",
    "\n",
    "## copy..\n",
    "\n",
    "## Get the one hot vector of the action taken (useful for take in consideration only the Q value of action previouly considerated)\n",
    "## Of all the other actions isn't clear the estimantes Q_values\n",
    "\n",
    "\n",
    "X_action = tf.placeholder(tf.int32, shape=(None,))\n",
    "Q_action = tf.reduce_sum(secondQ_outputs * tf.one_hot(X_action, n_outputs), axis=-1, keep_dims=True)\n",
    "\n",
    "copy_op = [tf.assign(main_name, secondQ[var_name]) for var_name, main_name in mainQ.items()]\n",
    "copy_second_to_main = tf.group(*copy_op)\n",
    "\n",
    "#mainQ_W = [mainQ[var_name] for var_name, _ in mainQ.items()]\n",
    "#secondQ_W = [secondQ[var_name] for var_name, _ in secondQ.items()]\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=(None,1))\n",
    "loss = tf.reduce_mean(tf.square(y - Q_action))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "loss_summary = tf.summary.scalar('LOSS', loss) #loss_summary = \n",
    "merge_summary = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "---- 0 --- 647 -- 160.0 ----\n",
      "Epsilon: 0.9987707\n",
      "Counter({'[0]': 647})\n",
      "TEST: 433 \t 60.0 Counter({'0': 433})\n",
      "---- 1 --- 667 -- 220.0 ----\n",
      "Epsilon: 0.9975034\n",
      "Counter({'[0]': 667})\n",
      "TEST: 437 \t 60.0 Counter({'0': 437})\n",
      "---- 2 --- 638 -- 180.0 ----\n",
      "Epsilon: 0.9962912\n",
      "Counter({'[0]': 638})\n",
      "TEST: 435 \t 60.0 Counter({'0': 435})\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "---- 3 --- 785 -- 290.0 ----\n",
      "Epsilon: 0.9947997\n",
      "Counter({'[5]': 300, '[2]': 200, '[0]': 148, '[8]': 100, '[3]': 37})\n",
      "TEST: 440 \t 60.0 Counter({'3': 440})\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "---- 4 --- 607 -- 160.0 ----\n",
      "Epsilon: 0.9936464\n",
      "Counter({'[7]': 424, '[3]': 183})\n",
      "TEST: 432 \t 60.0 Counter({'3': 432})\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "Copying..\n",
      "---- 5 --- 402 -- 70.0 ----\n",
      "Epsilon: 0.9928826\n",
      "Counter({'[3]': 202, '[7]': 200})\n",
      "TEST: 430 \t 60.0 Counter({'3': 430})\n",
      "Copying..\n",
      "Copying..\n"
     ]
    }
   ],
   "source": [
    "print(learning_rate)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for i in range(num_games):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        epoch = 0\n",
    "        game_reward = 0\n",
    "        actions_counter = Counter() \n",
    "        \n",
    "        while not done:\n",
    "            obs = preprocess_observation(obs)\n",
    "            actions = mainQ_outputs.eval(feed_dict={X:[obs], in_training_mode:False})\n",
    "\n",
    "            ## GET ACTION'S ONE HOT VECTOR\n",
    "            action = np.argmax(actions, axis=-1)\n",
    "            actions_counter[str(action)] += 1 \n",
    "            action = expl_policy(action, global_step)\n",
    "            \n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "\n",
    "            ## UPDATE EXPERIENCE MEMORIES WITH THE LAST ONE\n",
    "            memories.append([obs, action, preprocess_observation(new_obs), reward, done])\n",
    "            \n",
    "            \n",
    "            if global_step % steps_train == 0 and global_step > start_steps:\n",
    "                ## TRAIN THE SECOND Q\n",
    "                o_obs, o_act, o_next_obs, o_rew, o_done = get_memories(batch_size)\n",
    "\n",
    "                o_obs = [x for x in o_obs]\n",
    "                o_next_obs = [x for x in o_next_obs]\n",
    "\n",
    "                next_act = mainQ_outputs.eval(feed_dict={X:o_next_obs, in_training_mode:False})\n",
    "                y_batch = o_rew + discount_factor * np.max(next_act, axis=-1) * (1-o_done) ## IS IT CORRECT??\n",
    "                '''\n",
    "                if global_step % (steps_train+800) == 0:\n",
    "                    print('actions', actions)\n",
    "                    print('arg next_act action',np.argmax(next_act, axis=-1))\n",
    "                    print('y_batch',y_batch)\n",
    "                    '''\n",
    "            \n",
    "                mrg_summary = merge_summary.eval(feed_dict={X:o_obs, y:np.expand_dims(y_batch, axis=-1), X_action:o_act, in_training_mode:False}) ## IS IT CORRECT?\n",
    "                file_writer.add_summary(mrg_summary, global_step)\n",
    "\n",
    "                train_loss, _ = sess.run([loss, training_op], feed_dict={X:o_obs, y:np.expand_dims(y_batch, axis=-1), X_action:o_act, in_training_mode:True})\n",
    "            \n",
    "            ## COPY SECOND IN FIRST\n",
    "            if (global_step+1) % copy_steps == 0 and global_step > start_steps:\n",
    "                print('Copying..')\n",
    "                copy_second_to_main.run()\n",
    "                \n",
    "            \n",
    "            obs = new_obs\n",
    "            epoch += 1\n",
    "            global_step += 1\n",
    "            game_reward += reward\n",
    "        \n",
    "        print('----', i, '---', epoch, '--', game_reward,'----')\n",
    "        expl_policy(3, global_step, print_ep=True)\n",
    "        print(actions_counter)\n",
    "        \n",
    "        ## TEST THE ACTOR\n",
    "        obs = env.reset()\n",
    "        test_ep = 0\n",
    "        test_reward = 0\n",
    "        test_done = False\n",
    "        test_actions_counter = Counter() \n",
    "        while not test_done:\n",
    "            obs = preprocess_observation(obs)\n",
    "            action = mainQ_outputs.eval(feed_dict={X:[obs], in_training_mode:False})\n",
    "            test_actions_counter[str(np.argmax(action))] += 1 \n",
    "            new_obs, reward, test_done, _ = env.step(np.argmax(action))\n",
    "            \n",
    "            obs = new_obs\n",
    "            test_ep += 1\n",
    "            test_reward += reward\n",
    "            \n",
    "        print('TEST:', test_ep, '\\t', test_reward, test_actions_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd C:\\Users\\Andrea\\Jupyter notebook\\Reinforcement Learning\\Pacman_rl\n",
    "# tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
